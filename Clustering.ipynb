{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from multiprocessing import Process, Queue\n",
    "from twisted.internet import reactor\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import html2text\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import KMeans, OPTICS, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import hdbscan\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host='localhost', database='discogs3', user='root', password='root')\n",
    "cursor = conn.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_k_means():\n",
    "    cursor.execute(\"\"\"SELECT a.versions, a.released, GROUP_CONCAT(DISTINCT g.genre), GROUP_CONCAT(DISTINCT s.style), a.album_name FROM album a, album_genre g, album_style s \n",
    "                        WHERE a.id = g.album_id AND a.id = s.album_id GROUP BY a.id\"\"\")\n",
    "    return pd.DataFrame(cursor.fetchall())\n",
    "    \n",
    "data = get_data_for_k_means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building one-hot encoded features for styles\n",
    "\n",
    "all_style_features_lst = []\n",
    "for idx, x in enumerate(data[3]):\n",
    "    if x:\n",
    "        corrected = []\n",
    "        for w in x.split(','):\n",
    "            corrected += [re.sub('\\W+', '', w.lower())]\n",
    "        \n",
    "        data.at[idx, 3] = corrected\n",
    "        all_style_features_lst += corrected\n",
    "        \n",
    "all_style_features_lst = list(set(all_style_features_lst))\n",
    "all_style_features = {}\n",
    "\n",
    "for idx, x in enumerate(all_style_features_lst):\n",
    "    all_style_features[x] = idx\n",
    "    \n",
    "style_feature_vector = []\n",
    "for x in data[3]:\n",
    "    feature_v = np.zeros(len(all_style_features) + 1)\n",
    "    if x:\n",
    "        for w in x:\n",
    "            feature_v[all_style_features[w]] = 1\n",
    "    else: feature_v[-1] = 1\n",
    "    style_feature_vector.append(feature_v)\n",
    "        \n",
    "print('Features from styles have the following shape (one-hot encoded): ', np.shape(style_feature_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building one-hot encoded features for genres\n",
    "\n",
    "all_genre_features_lst = []\n",
    "for idx, x in enumerate(data[2]):\n",
    "    if x:\n",
    "        corrected = []\n",
    "        for w in x.lower().split(','):\n",
    "            corrected += [re.sub('\\W+', '', w.lower())]\n",
    "        \n",
    "        data.at[idx, 2] = corrected\n",
    "        all_genre_features_lst += corrected\n",
    "    else: all_genre_features_lst.append(None)\n",
    "        \n",
    "all_genre_features_lst_unq = list(set(all_genre_features_lst))\n",
    "all_genre_features = {}\n",
    "\n",
    "for idx, x in enumerate(all_genre_features_lst_unq):\n",
    "    all_genre_features[x] = idx\n",
    "    \n",
    "genre_feature_vector = []\n",
    "for x in data[2]:\n",
    "    feature_v = np.zeros(len(all_genre_features) + 1)\n",
    "    if x:\n",
    "        for w in x:\n",
    "            feature_v[all_genre_features[w]] = 1\n",
    "    else: feature_v[-1] = 1\n",
    "    genre_feature_vector.append(feature_v)\n",
    "        \n",
    "print('Features from genres have the following shape (one-hot encoded): ', np.shape(genre_feature_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building features for release year\n",
    "\n",
    "all_year_features_lst = []\n",
    "\n",
    "for idx, x in enumerate(data[1]):\n",
    "    if x:\n",
    "        all_year_features_lst.append([x.year])\n",
    "        data.at[idx, 1] = x.year\n",
    "    else: \n",
    "        all_year_features_lst.append([-1])\n",
    "\n",
    "print('Features from release year have the following shape: ', np.shape(all_year_features_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building features for number of released versions\n",
    "\n",
    "all_version_feature_lst = []\n",
    "\n",
    "for idx, x in enumerate(data[0]):\n",
    "    if x:\n",
    "        all_version_feature_lst.append([x])\n",
    "    else: all_version_feature_lst.append([-1])\n",
    "        \n",
    "print('Features from versions have the following shape: ', np.shape(all_version_feature_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a value for the number of clusters\n",
    "K = 25\n",
    "\n",
    "# Choose the features used for clusterisation. Options are: year, versions, style, genre. Put values in the list below as strings and run subsequent cells for example generation and clusterings\n",
    "FEATURES = [\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making input examples and running PCA if there are any one-hot encoded features, as both KMeans and HDBSCAN do not handle categorical data\n",
    "\n",
    "examples = np.empty((len(data), 1), dtype=np.int)\n",
    "for f in FEATURES:\n",
    "    if f == 'year':\n",
    "        examples = np.concatenate((examples, all_year_features_lst), axis=1)\n",
    "    elif f == 'versions':\n",
    "        examples = np.concatenate((examples, all_version_feature_lst), axis=1)\n",
    "    elif f == 'style':\n",
    "        examples = np.concatenate((examples, style_feature_vector), axis=1)\n",
    "    elif f == 'genre':\n",
    "        examples = np.concatenate((examples, genre_feature_vector), axis=1)\n",
    "\n",
    "examples = examples[:, 1:]\n",
    "\n",
    "if np.shape(examples)[1] > 2:\n",
    "    pca = PCA(n_components=round(math.sqrt(np.shape(examples)[1])))\n",
    "    examples = pca.fit_transform(examples)\n",
    "    print('PCA done')\n",
    "\n",
    "print(np.shape(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans clustering with the above examples and K value\n",
    "\n",
    "kmeans = KMeans(n_clusters=K)\n",
    "kmeans.fit(examples)\n",
    "y_kmeans = kmeans.predict(examples)\n",
    "\n",
    "for i in range(len(y_kmeans)):\n",
    "    print(data.iloc[[i], [4, 2, 3, 1, 0]].to_string(index=False, header=False), ' -- cluster --> ', y_kmeans[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN clustering\n",
    "\n",
    "cluster = hdbscan.HDBSCAN(metric=\"chebyshev\")\n",
    "cluster.fit(examples)\n",
    "\n",
    "for i in range(len(cluster.labels_)):\n",
    "    print(data.iloc[[i], [4, 2, 3, 1, 0]].to_string(index=False, header=False), ' -- cluster --> ', cluster.labels_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
